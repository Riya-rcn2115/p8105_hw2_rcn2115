p8105_hw2_rcn2115
================
Riya Nadkarni

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(dplyr)

library(readxl)
```

# Problem 1

## Importing and cleaning Data

``` r
subway_df <- 
  
read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv",na = c("NA",".","")) |>
  
  janitor::clean_names() |>
  
  select(line:entry, 
         vending, 
         ada) |>
  
  mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )
  )
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#print(subway_df)
```

## Description of Dataset

The NYC Transit Subway dataset provides information on subway station
entrances and exits across New York City. After importing the data, I
standardized the column names and addressed missing values by converting
“NA”, “.”, and empty strings to NA. I selected key columns for analysis,
including `line`, `station_name`, `station_latitude` and
`station_longitude`, `routes` , `entrance_type` , `entry`, `vending` and
`ada`. The `entry` variable was converted from a character (“YES”/“NO”)
to a logical variable (TRUE for “YES”, FALSE for “NO”). The resulting
dataset has 1868 rows and 19 columns. However, the data isn’t tidy, as
there are separate columns for each of the 11 routes served.

## Distinct Stations

``` r
distinct_stations <- subway_df |>
  
  distinct(line, 
           station_name) |>
  
  nrow()

#print(distinct_stations)
```

There are 465 distinct stations.

## ADA Stations

``` r
ada_stations <- subway_df |>
  
  filter(ada == TRUE) |> 
  
  distinct(line, station_name) |> 
  
  nrow() 

#print(ada_stations)
```

There are 84 stations that are ADA compliant.

## No Vending Stations

``` r
no_vending_entry <- subway_df |>
  
  filter(vending == "NO", 
         entry == TRUE) |>
  
  nrow() 

no_vending <- subway_df |>
  
  filter(vending == "NO")|>
  
  nrow()

#print(no_vending_entry)
#print(no_vending)
```

The proportion of no vending stations that allow entry is 0.3770492.

## Reformatting Route Name and Route Number

``` r
subway_reformat_df <- 
  
  subway_df |>
  
  mutate(
    across(
      starts_with("route"), 
      as.character)
    )|> 
  
  pivot_longer(
    
    cols = starts_with("route"), 
    
    names_to = "route_number", 
    
    values_to = "route_name",
    
    values_drop_na = TRUE
    
    ) 
```

## A Train!

``` r
distinct_a_stations <- subway_reformat_df |>
  
  filter(route_name == "A") |> 
  
  distinct(line, 
           station_name) |> 
  
  nrow() 

ada_a_stations <- subway_reformat_df |>
  
  filter(route_name == "A", 
         ada == TRUE) |> 
  
  distinct(line, station_name) |> 
  
  nrow()

#print(distinct_a_stations)
#print(ada_a_stations)
```

There are 60 distinct A stations and 17ADA compliant A stations.

# Problem 2

## Read and Clean Mr. Trash Wheel

``` r
mr_trash_wheel_df <- read_excel("./202409 Trash Wheel Collection Data.xlsx",
             na = c("NA",".",""), 
             sheet = "Mr. Trash Wheel", 
             range = "A2:N653"
             ) |>
  
  janitor::clean_names() |>
  
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    trash_wheel = "mr_trash_wheel",
    year = as.integer(year)
    ) |>
  
  relocate(trash_wheel, dumpster)

#print(mr_trash_wheel_df)
#view(mr_trash_wheel_df)
```

## Read and Clean Professor Trash Wheel and Gwynnda Trash Wheel

``` r
professor_trash_wheel_df <- read_excel("./202409 Trash Wheel Collection Data.xlsx", 
             na = c("NA",".",""), 
             sheet = "Professor Trash Wheel", 
             range = "A2:M120", 
             ) |>
  
  janitor::clean_names() |>
  
  mutate(
    trash_wheel = "professor_trash_wheel",
    year = as.integer(year)
    ) |>
  
    relocate(trash_wheel, dumpster)

gwynnda_trash_wheel_df <- read_excel("./202409 Trash Wheel Collection Data.xlsx", 
             na = c("NA",".",""), 
             sheet = "Gwynnda Trash Wheel", 
             range = "A2:L265", 
             ) |>
  
  janitor::clean_names() |>
  
  mutate(
    trash_wheel = "gwynnda_trash_wheel",
    year = as.integer(year)
    ) |>
  
    relocate(trash_wheel, dumpster)

#print(professor_trash_wheel_df)
#print(gwynnda_trash_wheel_df)
#view(professor_trash_wheel_df)
#view(gwynnda_trash_wheel_df)
```

# Combining Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel

``` r
all_trash_wheel_df <- bind_rows(mr_trash_wheel_df, professor_trash_wheel_df, gwynnda_trash_wheel_df) |>
  
  janitor::clean_names() |>
  
  relocate(trash_wheel, dumpster) 

#print(all_trash_wheel_df)
#view(all_trash_wheel_df)
```

## Description of dataset

This dataset (`all_trash_wheel_df`) is a combination of Mr. Trash Wheel,
Professor Trash Wheel, and Gwynnda Trash Wheel datasets, each of which
are vessels that remove trash. The key variables included were
`dumpster` `number`, `month`, `year`, `date`, `weight`, `volume`,
`plastic bottles`, `polystyrene`, `cigarette buds`, `glass bottles` ,
`plastic bags`, `wrappers`, `sports balls` and `homes powered`. This
dataset has a total of 1032 observations. The resulting dataset has 1032
rows and 15 columns.

The total weight of trash collected by Professor Trash Wheel was 246.74
tons. Gwynnda collected a total of 1.812^{4} cigarette butts from the
water in June 2022.

# Problem 3

## Import Bakers

``` r
bakers_df <- read_csv("./gbb_datasets/gbb_datasets/bakers.csv", 
           na = c("NA", ".", "")
           ) |> 
  
  janitor::clean_names() |>
  
  na.omit(bakers_df) |>
  
  separate(
    baker_name, 
    into = c("baker_first_name", 
             "baker_last_name"), 
    sep = " "
  ) |> 
  
  arrange(series)
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#print(bakers_df)
#view(bakers_df)
```

## Import Bakes

``` r
bakes_df <- read_csv("./gbb_datasets/gbb_datasets/bakes.csv", 
                     na = c("NA", ".", "")
                     ) |> 
  
  janitor::clean_names() |>
  
  mutate(
    baker = str_replace_all(baker, '"Jo"', "Jo")
  ) |> 
  
  rename("baker_first_name" = "baker") |>
  
  relocate(baker_first_name)
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#print(bakes_df)
#view(bakes_df)
```

## Import Results

``` r
results_df <- read_csv("./gbb_datasets/gbb_datasets/results.csv", 
           na = c("NA", ".", ""), 
           skip = 2) |>
  
  janitor::clean_names() |>
  
  arrange(series,baker) |>
  
  mutate(
   baker = ifelse(row_number() == 57:64, 
                  "Jo", 
                  baker)
  ) |> 
  
  rename("baker_first_name" = "baker") |>
  
  relocate(baker_first_name)
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#print(results_df)
#view(results_df)
```

## Check for Completeness with Anti-join

``` r
bakes_missing_df = anti_join(bakers_df, bakes_df)
```

    ## Joining with `by = join_by(baker_first_name, series)`

``` r
results_missing_df = anti_join(bakers_df, results_df)
```

    ## Joining with `by = join_by(baker_first_name, series)`

## Merge Into a Single Dataset

``` r
gbb_bakes_results_df <-
  left_join(bakes_df, 
            results_df, 
            by = c("baker_first_name", 
                   "series", 
                   "episode")
            ) 

gbb_bakes_results_bakers_df <- 
  left_join(gbb_bakes_results_df, 
            bakers_df, 
            by = c("baker_first_name", 
                   "series")
            ) |>
  
  relocate(baker_first_name, baker_last_name, series, episode)

write_csv(gbb_bakes_results_bakers_df, "gbb_datasets/gbb_combined_df.csv")
```

## Description of data cleaning process and dataset

For the bakers dataset,I read in the `bakers.csv` dataset using
`read_csv()`. I used `janitor::clean_names()` to clean column names and
ensure they were in snake_case naming convention. The `baker_name`
column was split into two columns, `baker` (first name) and
`baker_last_name` (last name), using the separate() function. The data
was sorted by the `series` column.

I used the same approach for the `bakes.csv` dataset. I used the
`mutate()` function to replace any occurrences of `"Jo"` within quotes
with `Jo` without quotes to standardize name format.

The `results.csv` dataset was read in with `skip = 2` to account for
header rows.For consistency, the dataset was ordered by both `series`
and `baker` and Joanne’s name was replaced with `"Jo"` using `ifelse()`.

I used the `anti_join()` function to find missing data.
`bakes_missing_df` was created by performing an anti-join between
`bakers_df` and `bakes_df`.I similarly created `results_missing_df`.

I merged `bakes_df` and `results_df` on common columns `baker`,
`series`, and `episode` using `left_join()`. The combined dataset
(`gbb_df`) was joined with `bakers_df` on `baker` and `series`. The
resulting dataset was reorganized using `relocate()` so that important
variables (`series`, `episode`, `baker`, and `baker_last_name`) appeared
at the beginning.I used `na.omit()` to remove missing values.

The final dataset `gbb_bakes_results__bakers_df` tells us about bakers,
their bakes, and competition results from the Great British Bake-Off. It
includes key variables such as series, episode and baker names.

The resulting dataset has 548 rows and 11 columns.

## Creating a Table

``` r
winner_df <- results_df |> 
  
  filter(series <= 10, series >=5) |> 
  
  filter(result %in% c("WINNER", "STAR BAKER"))  |> 
  
  select(series, episode, baker_first_name, result)

winner_df |>
  
  pivot_wider(
    names_from = series,
    values_from = baker_first_name
  ) |> 
  
  arrange(episode) |> 
  
  knitr::kable()
```

| episode | result     | 5       | 6      | 7         | 8      | 9       | 10       |
|--------:|:-----------|:--------|:-------|:----------|:-------|:--------|:---------|
|       1 | STAR BAKER | Nancy   | Marie  | Jane      | Steven | Manon   | Michelle |
|       2 | STAR BAKER | Richard | Ian    | Candice   | Steven | Rahul   | Alice    |
|       3 | STAR BAKER | Luis    | Ian    | Tom       | Julia  | Rahul   | Michael  |
|       4 | STAR BAKER | Richard | Ian    | Benjamina | Kate   | Dan     | Steph    |
|       5 | STAR BAKER | Kate    | Nadiya | Candice   | Sophie | Kim-Joy | Steph    |
|       6 | STAR BAKER | Chetna  | Mat    | Tom       | Liam   | Briony  | Steph    |
|       7 | STAR BAKER | Richard | Tamal  | Andrew    | Steven | Kim-Joy | Henry    |
|       8 | STAR BAKER | Richard | Nadiya | Candice   | Stacey | Ruby    | Steph    |
|       9 | STAR BAKER | Richard | Nadiya | Andrew    | Sophie | Ruby    | Alice    |
|      10 | WINNER     | Nancy   | Nadiya | Candice   | Sophie | Rahul   | David    |

This table, which highlights the star bakers and winners from seasons 5
to 10, suggests a pattern of predictability in the overall winners. For
instance, Candace, the winner of season 7, was named star baker more
often than any other contestant in that season. Season 10 stands out as
the only season where the winner, David, had never been a star baker
during the competition.

## Import Viewers:

``` r
viewers_df <- read_csv("./gbb_datasets/gbb_datasets/viewers.csv",
           na = c("NA", ".", "")
           ) |>
  
  janitor::clean_names() |>
  
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewership",
    names_prefix = "series_"
  ) |>
  
  mutate(
    series = as.numeric(series)
  ) |>
  
  arrange(series) |>
  
  relocate (series)
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
knitr::kable(head(viewers_df, 10), 
             caption = "First 10 rows of GBB Viewers Dataset")
```

| series | episode | viewership |
|-------:|--------:|-----------:|
|      1 |       1 |       2.24 |
|      1 |       2 |       3.00 |
|      1 |       3 |       3.00 |
|      1 |       4 |       2.60 |
|      1 |       5 |       3.03 |
|      1 |       6 |       2.75 |
|      1 |       7 |         NA |
|      1 |       8 |         NA |
|      1 |       9 |         NA |
|      1 |      10 |         NA |

First 10 rows of GBB Viewers Dataset

# Season 1 and Season 5 Average Viewers

``` r
viewers_season_1_avg <- viewers_df |> 
  
  filter(series == "1") |>
  
  summarise(mean(viewership, na.rm = TRUE))

viewers_season_5_avg <- viewers_df |> 
  
  filter(series == "5") |>
  
  summarise(mean(viewership, na.rm = TRUE))
```

The season 1 has an average viewership of 2.77and season 5 has an
average viewership of is 10.0393.
