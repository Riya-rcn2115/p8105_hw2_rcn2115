---
title: "p8105_hw2_rcn2115"
author: "Riya Nadkarni"
output: github_document
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

```{r Load the Libraries}

library(tidyverse)

library(dplyr)

library(readxl)

```

# Problem 1

## Importing and cleaning Data

```{r Importing and Cleaning Data}

subway_df <- 
  
read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv",na = c("NA",".","")) |>
  
  janitor::clean_names() |>
  
  select(line:entry, 
         vending, 
         ada) |>
  
  mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )
  )

#print(subway_df)

```

## Description of Dataset

The NYC Transit Subway dataset provides information on subway station entrances and exits across New York City. After importing the data, I standardized the column names and addressed missing values by converting "NA", ".", and empty strings to NA. I selected key columns for analysis, including  `line`, `station_name`, `station_latitude` and `station_longitude`, `routes` , `entrance_type` , `entry`, `vending` and `ada`. The `entry` variable was converted from a character ("YES"/"NO") to a logical variable (TRUE for "YES", FALSE for "NO"). The resulting dataset has `r nrow(subway_df)` rows and `r ncol(subway_df)` columns. However, the data isn't tidy, as there are separate columns for each of the 11 routes served.

## Distinct Stations 

```{r Distinct Stations}

distinct_stations <- subway_df |>
  
  distinct(line, 
           station_name) |>
  
  nrow()

#print(distinct_stations)

```

There are `r nrow(distinct(subway_df, line, station_name))` distinct stations. 

## ADA Stations

```{r ADA Stations}

ada_stations <- subway_df |>
  
  filter(ada == TRUE) |> 
  
  distinct(line, station_name) |> 
  
  nrow() 

#print(ada_stations)

```

There are `r ada_stations` stations that are ADA compliant. 

## No Vending Stations

```{r No Vending Stations}

no_vending_entry <- subway_df |>
  
  filter(vending == "NO", 
         entry == TRUE) |>
  
  nrow() 

no_vending <- subway_df |>
  
  filter(vending == "NO")|>
  
  nrow()

#print(no_vending_entry)
#print(no_vending)

```

The proportion of no vending stations that allow entry is `r no_vending_entry/no_vending`.

## Reformatting Route Name and Route Number 

```{r Reformatting Route Name and Route Number}

subway_reformat_df <- 
  
  subway_df |>
  
  mutate(
    across(
      starts_with("route"), 
      as.character)
    )|> 
  
  pivot_longer(
    
    cols = starts_with("route"), 
    
    names_to = "route_number", 
    
    values_to = "route_name",
    
    values_drop_na = TRUE
    
    ) 

```

## A Train! 

```{r A Train!}

distinct_a_stations <- subway_reformat_df |>
  
  filter(route_name == "A") |> 
  
  distinct(line, 
           station_name) |> 
  
  nrow() 

ada_a_stations <- subway_reformat_df |>
  
  filter(route_name == "A", 
         ada == TRUE) |> 
  
  distinct(line, station_name) |> 
  
  nrow()

#print(distinct_a_stations)
#print(ada_a_stations)

```

There are `r distinct_a_stations` distinct A stations and `r ada_a_stations`ADA compliant A stations.  

# Problem 2

## Read and Clean Mr. Trash Wheel

```{r Read and Clean Mr. Trash Wheel}

mr_trash_wheel_df <- read_excel("./202409 Trash Wheel Collection Data.xlsx",
             na = c("NA",".",""), 
             sheet = "Mr. Trash Wheel", 
             range = "A2:N653"
             ) |>
  
  janitor::clean_names() |>
  
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    trash_wheel = "mr_trash_wheel",
    year = as.integer(year)
    ) |>
  
  relocate(trash_wheel, dumpster)

#print(mr_trash_wheel_df)
#view(mr_trash_wheel_df)

```

## Read and Clean Professor Trash Wheel and Gwynnda Trash Wheel

```{r Read and Clean Professor Treash Wheel and Gwynnda Trash Wheel}

professor_trash_wheel_df <- read_excel("./202409 Trash Wheel Collection Data.xlsx", 
             na = c("NA",".",""), 
             sheet = "Professor Trash Wheel", 
             range = "A2:M120", 
             ) |>
  
  janitor::clean_names() |>
  
  mutate(
    trash_wheel = "professor_trash_wheel",
    year = as.integer(year)
    ) |>
  
    relocate(trash_wheel, dumpster)

gwynnda_trash_wheel_df <- read_excel("./202409 Trash Wheel Collection Data.xlsx", 
             na = c("NA",".",""), 
             sheet = "Gwynnda Trash Wheel", 
             range = "A2:L265", 
             ) |>
  
  janitor::clean_names() |>
  
  mutate(
    trash_wheel = "gwynnda_trash_wheel",
    year = as.integer(year)
    ) |>
  
    relocate(trash_wheel, dumpster)

#print(professor_trash_wheel_df)
#print(gwynnda_trash_wheel_df)
#view(professor_trash_wheel_df)
#view(gwynnda_trash_wheel_df)

```

# Combining Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel 

```{r Combining Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel}

all_trash_wheel_df <- bind_rows(mr_trash_wheel_df, professor_trash_wheel_df, gwynnda_trash_wheel_df) |>
  
  janitor::clean_names() |>
  
  relocate(trash_wheel, dumpster) 

#print(all_trash_wheel_df)
#view(all_trash_wheel_df)

```


## Description of dataset
This dataset (`all_trash_wheel_df`) is a combination of Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel datasets, each of which are vessels that remove trash.
The key variables included were `dumpster` `number`, `month`, `year`, `date`, `weight`, `volume`, `plastic bottles`, `polystyrene`, `cigarette buds`, `glass bottles` , `plastic bags`, `wrappers`, `sports balls` and `homes powered`. This dataset has a total of `r nrow(all_trash_wheel_df)` observations. The resulting dataset has `r nrow(all_trash_wheel_df)` rows and `r ncol(all_trash_wheel_df)` columns. 

The total weight of trash collected by Professor Trash Wheel was `r professor_trash_wheel_df |> summarise(sum(weight_tons, na.rm = TRUE))` tons. Gwynnda collected a total of `r gwynnda_trash_wheel_df |> filter(month == "June", year =="2022") |> summarise(sum(cigarette_butts, na.rm = TRUE))` cigarette butts from the water in June 2022.

# Problem 3

## Import Bakers 

```{r Import Bakers}

bakers_df <- read_csv("./gbb_datasets/gbb_datasets/bakers.csv", 
           na = c("NA", ".", "")
           ) |> 
  
  janitor::clean_names() |>
  
  na.omit(bakers_df) |>
  
  separate(
    baker_name, 
    into = c("baker_first_name", 
             "baker_last_name"), 
    sep = " "
  ) |> 
  
  arrange(series)

#print(bakers_df)
#view(bakers_df)

```


## Import Bakes 

```{r Import Bakes}

bakes_df <- read_csv("./gbb_datasets/gbb_datasets/bakes.csv", 
                     na = c("NA", ".", "")
                     ) |> 
  
  janitor::clean_names() |>
  
  mutate(
    baker = str_replace_all(baker, '"Jo"', "Jo")
  ) |> 
  
  rename("baker_first_name" = "baker") |>
  
  relocate(baker_first_name)
  
  

#print(bakes_df)
#view(bakes_df)

```

## Import Results

```{r Import Results}

results_df <- read_csv("./gbb_datasets/gbb_datasets/results.csv", 
           na = c("NA", ".", ""), 
           skip = 2) |>
  
  janitor::clean_names() |>
  
  arrange(series,baker) |>
  
  mutate(
   baker = ifelse(row_number() == 57:64, 
                  "Jo", 
                  baker)
  ) |> 
  
  rename("baker_first_name" = "baker") |>
  
  relocate(baker_first_name)

#print(results_df)
#view(results_df)

```

## Check for Completeness with Anti-join


```{r Check for Completeness with Anti-Join}

bakes_missing_df = anti_join(bakers_df, bakes_df)

results_missing_df = anti_join(bakers_df, results_df)

```

## Merge Into a Single Dataset 

```{r Merge Into a Single Dataset }

gbb_bakes_results_df <-
  left_join(bakes_df, 
            results_df, 
            by = c("baker_first_name", 
                   "series", 
                   "episode")
            ) 

gbb_bakes_results_bakers_df <- 
  left_join(gbb_bakes_results_df, 
            bakers_df, 
            by = c("baker_first_name", 
                   "series")
            ) |>
  
  relocate(baker_first_name, baker_last_name, series, episode)

write_csv(gbb_bakes_results_bakers_df, "gbb_datasets/gbb_combined_df.csv")

```

## Description of data cleaning process and dataset

For the bakers dataset,I read in the `bakers.csv` dataset using `read_csv()`. I used `janitor::clean_names()` to clean column names and ensure they were in snake_case naming convention. The `baker_name` column was split into two columns, `baker` (first name) and `baker_last_name` (last name), using the separate() function. The data was sorted by the `series` column.

I used the same approach for the `bakes.csv` dataset. I used the `mutate()` function to replace any occurrences of `"Jo"` within quotes with `Jo` without quotes to standardize name format.

The `results.csv` dataset was read in with `skip = 2` to account for header rows.For consistency, the dataset was ordered by both `series` and `baker` and Joanne's name was replaced with `"Jo"` using `ifelse()`.

I used the `anti_join()` function to find missing data. `bakes_missing_df` was created by performing an anti-join between `bakers_df` and `bakes_df`.I similarly created `results_missing_df`.

I merged `bakes_df` and `results_df` on common columns `baker`, `series`, and `episode` using `left_join()`. The combined dataset (`gbb_df`) was joined with `bakers_df` on `baker` and `series`. The resulting dataset was reorganized using `relocate()` so that important variables (`series`, `episode`, `baker`, and `baker_last_name`) appeared at the beginning.I used `na.omit()` to remove missing values.

The final dataset `gbb_bakes_results__bakers_df` tells us about bakers, their bakes, and competition results from the Great British Bake-Off. It includes key variables such as series, episode and baker names.

The resulting dataset has `r nrow(gbb_bakes_results_bakers_df)` rows and `r ncol(gbb_bakes_results_bakers_df)` columns.


## Creating a Table 

```{r Creating a Table}

winner_df <- results_df |> 
  
  filter(series <= 10, series >=5) |> 
  
  filter(result %in% c("WINNER", "STAR BAKER"))  |> 
  
  select(series, episode, baker_first_name, result)

winner_df |>
  
  pivot_wider(
    names_from = series,
    values_from = baker_first_name
  ) |> 
  
  arrange(episode) |> 
  
  knitr::kable()

```
This table, which highlights the star bakers and winners from seasons 5 to 10, suggests a pattern of predictability in the overall winners. For instance, Candace, the winner of season 7, was named star baker more often than any other contestant in that season. Season 10 stands out as the only season where the winner, David, had never been a star baker during the competition. 

## Import Viewers: 

```{r Import Viewers}

viewers_df <- read_csv("./gbb_datasets/gbb_datasets/viewers.csv",
           na = c("NA", ".", "")
           ) |>
  
  janitor::clean_names() |>
  
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewership",
    names_prefix = "series_"
  ) |>
  
  mutate(
    series = as.numeric(series)
  ) |>
  
  arrange(series) |>
  
  relocate (series)

knitr::kable(head(viewers_df, 10), 
             caption = "First 10 rows of GBB Viewers Dataset")

```

# Season 1 and Season 5 Average Viewers

```{r Season 1 and Season 5 Average Viewers}

viewers_season_1_avg <- viewers_df |> 
  
  filter(series == "1") |>
  
  summarise(mean(viewership, na.rm = TRUE))

viewers_season_5_avg <- viewers_df |> 
  
  filter(series == "5") |>
  
  summarise(mean(viewership, na.rm = TRUE))

```

The season 1 has an average viewership of `r viewers_season_1_avg`and season 5 has an average viewership of is `r viewers_season_5_avg`. 



